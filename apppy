root@openai:/home/openai/langchain# nano app.py

from langchain_ollama import OllamaLLM
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
print("[1] Memuat model Gemma dari Ollama...")
llm = OllamaLLM(model="gemma:2b")
print("[2] Memuat dokumen...")
loader = TextLoader("docs/smartcity.txt")
documents = loader.load()
print(f"[2a] Jumlah dokumen: {len(documents)}")
print("[3] Memotong dokumen jadi chunks...")
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)
print(f"[3a] Jumlah potongan: {len(chunks)}")
print("[4] Membuat embeddings (HuggingFace)...")
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L6-v2")
print("[5] Membuat vectorstore Chroma...")
vectorstore = Chroma.from_documents(chunks, embedding)
print("[6] Mengaktifkan memory dan RAG chain...")
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    memory=memory,
)
print("‚úÖ Chatbot lokal aktif. Ketik 'exit' untuk keluar.\n")
while True:
    user_input = input("You: ")
    if user_input.lower() in ["exit", "quit"]:
        print("üîö Sesi dihentikan.")
        break
    response = qa_chain.invoke({"question": user_input})
#    response = qa_chain.run(user_input)
    print("Gemma:", response)
    print("üìù Chat history:", memory.chat_memory.messages[-2:])
